from langchain_core.tools import tool
from typing import Optional, Dict, List, Any, Union
import mongo.constants
import os
import json
import re
from glob import glob
from datetime import datetime
from orchestrator import Orchestrator, StepSpec, as_async
from qdrant.qdrant_initializer import RAGTool
# Qdrant and RAG dependencies
# try:
#     from qdrant_client import QdrantClient
#     from qdrant_client.models import Distance, VectorParams, PointStruct, Filter, FieldCondition, MatchValue
#     from sentence_transformers import SentenceTransformer
#     import numpy as np
# except ImportError:
#     QdrantClient = None
#     SentenceTransformer = None
#     np = None

mongodb_tools = mongo.constants.mongodb_tools
DATABASE_NAME = mongo.constants.DATABASE_NAME
try:
    from planner import plan_and_execute_query
except ImportError:
    plan_and_execute_query = None


def normalize_mongodb_types(obj: Any) -> Any:
    """Convert MongoDB extended JSON types to regular Python types."""
    if obj is None:
        return None

    if isinstance(obj, dict):
        # Handle MongoDB-specific types
        if '$binary' in obj:
            # Convert binary to string representation (we'll filter it out anyway)
            return f"<binary:{obj['$binary']['base64'][:8]}...>"
        elif '$date' in obj:
            # Convert MongoDB date to string representation
            return obj['$date']
        elif '$oid' in obj:
            # Convert ObjectId to string
            return obj['$oid']
        else:
            # Recursively process nested objects
            return {key: normalize_mongodb_types(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        # Process lists recursively
        return [normalize_mongodb_types(item) for item in obj]
    else:
        # Return primitive types as-is
        return obj


def filter_meaningful_content(data: Any) -> Any:
    """Filter MongoDB documents to keep only meaningful content fields.

    Removes unnecessary fields like _id, timestamps, and other metadata
    while preserving actual content like text, names, descriptions, etc.

    Args:
        data: Raw MongoDB document(s) - can be dict, list, or other types

    Returns:
        Filtered data with only meaningful content fields
    """
    # First, normalize MongoDB extended JSON to regular Python types
    normalized_data = normalize_mongodb_types(data)

    # Handle edge cases
    if normalized_data is None:
        return None

    # Define fields that contain meaningful content (not metadata)
    CONTENT_FIELDS = {
        # Text content
        'title', 'description', 'name', 'content', 'email', 'role',
        'priority', 'status', 'state', 'displayBugNo', 'projectDisplayId',
        # Business logic fields
        'label', 'type', 'access', 'visibility', 'icon', 'imageUrl',
        'business', 'staff', 'createdBy', 'assignee', 'project', 'cycle', 'module',
        'members', 'pages', 'projectStates', 'subStates', 'linkedCycle', 'linkedModule',
        # Date fields (but not timestamps)
        'startDate', 'endDate', 'joiningDate', 'createdAt', 'updatedAt',
        # Count/aggregation results
        'total', 'count', 'group', 'items'
    }

    # Fields to always exclude (metadata)
    EXCLUDE_FIELDS = {
        '_id', 'createdTimeStamp', 'updatedTimeStamp',
        '_priorityRank',  # Helper field added by pipeline
        '_class',  # Drop Java class metadata
    }

    def is_meaningful_field(key: str, value: Any) -> bool:
        """Check if a field contains meaningful content."""
        # Always exclude metadata fields
        if key in EXCLUDE_FIELDS:
            return False

        # Keep content fields
        if key in CONTENT_FIELDS:
            return True

        # For unknown fields, check if they have meaningful values
        if isinstance(value, str) and value.strip():
            # Non-empty strings are meaningful
            return True
        elif isinstance(value, (int, float)) and not key.endswith(('Id', '_id')):
            # Numbers that aren't IDs are meaningful
            return True
        elif isinstance(value, bool):
            # Boolean values are meaningful
            return True
        elif isinstance(value, dict):
            # Recursively check nested objects
            return any(is_meaningful_field(k, v) for k, v in value.items())
        elif isinstance(value, list) and value:
            # Check if list contains meaningful content, including dict items
            for item in value:
                if isinstance(item, (str, int, float, bool)):
                    if not isinstance(item, str) or item.strip():
                        return True
                elif isinstance(item, dict):
                    if any(is_meaningful_field(k, v) for k, v in item.items()):
                        return True
            return False

        return False

    def clean_document(doc: Any) -> Any:
        """Clean a single document or value."""
        if isinstance(doc, dict):
            # Filter dictionary
            cleaned = {}
            for key, value in doc.items():
                if is_meaningful_field(key, value):
                    if isinstance(value, (dict, list)):
                        cleaned_value = clean_document(value)
                        if cleaned_value:  # Only add if there's meaningful content
                            cleaned[key] = cleaned_value
                    else:
                        cleaned[key] = value
            return cleaned if cleaned else {}
        elif isinstance(doc, list):
            # Filter list of documents
            cleaned = []
            for item in doc:
                cleaned_item = clean_document(item)
                if cleaned_item:  # Only add if there's meaningful content
                    cleaned.append(cleaned_item)
            return cleaned
        else:
            # Return primitive values as-is
            return doc

    return clean_document(normalized_data)


def _is_hex_object_id(value: str) -> bool:
    try:
        return isinstance(value, str) and len(value) == 24 and all(c in '0123456789abcdefABCDEF' for c in value)
    except Exception:
        return False


def _is_binary_placeholder(value: Any) -> bool:
    return isinstance(value, str) and value.startswith("<binary:")


def _is_uuid_string(value: Any) -> bool:
    if not isinstance(value, str):
        return False
    # Simple UUID v4-like pattern check
    if len(value) != 36:
        return False
    parts = value.split("-")
    if len(parts) != 5:
        return False
    expected_lengths = [8, 4, 4, 4, 12]
    for part, L in zip(parts, expected_lengths):
        if len(part) != L:
            return False
        if not all(c in '0123456789abcdefABCDEF' for c in part):
            return False
    return True


def _is_id_like_key(key: str) -> bool:
    # Allowlist display ids
    ALLOWLIST = {"projectDisplayId"}
    if key in ALLOWLIST:
        return False
    lowered = key.lower()
    return (
        key == "_id"
        or lowered == "id"
        or lowered.endswith("id")  # memberId, projectId, defaultAsigneeId, etc.
        or lowered.endswith("_id")
        or lowered.endswith("uuid")
    )


def _strip_ids(value: Any) -> Any:
    """Recursively remove id/uuid-like fields and raw id values from documents."""
    if isinstance(value, dict):
        cleaned: Dict[str, Any] = {}
        for k, v in value.items():
            if _is_id_like_key(k):
                # drop id-like keys entirely
                continue
            # Recurse first
            v2 = _strip_ids(v)
            # Drop values that are just IDs or binary placeholders
            if isinstance(v2, str) and (_is_hex_object_id(v2) or _is_uuid_string(v2) or _is_binary_placeholder(v2)):
                continue
            if v2 is None:
                continue
            # Drop empty containers
            if isinstance(v2, (dict, list)) and not v2:
                continue
            cleaned[k] = v2
        return cleaned
    if isinstance(value, list):
        items = [_strip_ids(x) for x in value]
        items = [x for x in items if x not in (None, {}) and not (isinstance(x, str) and (_is_hex_object_id(x) or _is_uuid_string(x) or _is_binary_placeholder(x)))]
        return items
    return value


def _ensure_list_of_names(obj: Any) -> List[str]:
    names: List[str] = []
    if isinstance(obj, list):
        for item in obj:
            if isinstance(item, dict):
                name = item.get("name") or item.get("title")
                if isinstance(name, str) and name.strip():
                    names.append(name)
            elif isinstance(item, str) and item.strip() and not _is_hex_object_id(item) and not _is_binary_placeholder(item):
                names.append(item)
    elif isinstance(obj, dict):
        name = obj.get("name") or obj.get("title")
        if isinstance(name, str) and name.strip():
            names.append(name)
    elif isinstance(obj, str) and obj.strip():
        names.append(obj)
    return names


def _transform_by_collection(doc: Dict[str, Any], collection: Optional[str]) -> Dict[str, Any]:
    if not isinstance(doc, dict):
        return doc  # type: ignore[return-value]

    collection = (collection or "").strip()
    out: Dict[str, Any] = {}

    def copy_if_present(key: str, alias: Optional[str] = None):
        val = doc.get(key)
        if val is not None:
            out[alias or key] = val

    # Common flatteners
    def set_name(source_key: str, target_key: str):
        val = doc.get(source_key)
        if isinstance(val, dict):
            name = val.get("name") or val.get("title")
            if name:
                out[target_key] = name

    def set_names_list(source_key: str, target_key: str):
        val = doc.get(source_key)
        names = _ensure_list_of_names(val)
        if names:
            out[target_key] = names

    # Always useful common keys
    for k in ["title", "name", "description", "status", "priority", "label",
              "visibility", "access", "imageUrl", "icon",
              "favourite", "isFavourite", "isActive", "isArchived",
              "content", "displayBugNo", "projectDisplayId",
              "startDate", "endDate", "createdAt", "updatedAt"]:
        if k in doc:
            out[k] = doc[k]

    # Per collection enrichments
    if collection == "workItem":
        set_name("project", "projectName")
        set_name("state", "stateName")
        set_name("stateMaster", "stateMasterName")
        set_name("cycle", "cycleName")
        # modules in schema is a single subdoc despite plural key
        set_name("modules", "moduleName")
        set_name("business", "businessName")
        set_name("createdBy", "createdByName")
        set_names_list("assignee", "assignees")
        set_names_list("updatedBy", "updatedByNames")

    elif collection == "project":
        set_name("business", "businessName")
        set_name("lead", "leadName")
        set_name("defaultAsignee", "defaultAssigneeName")
        set_name("createdBy", "createdByName")
        copy_if_present("leadMail")

    elif collection == "cycle":
        # Project may only contain id; we skip if name isn't present
        set_name("project", "projectName")
        set_name("business", "businessName")

    elif collection == "module":
        set_name("project", "projectName")
        set_name("lead", "leadName")
        set_name("business", "businessName")
        set_names_list("assignee", "assignees")

    elif collection == "members":
        set_name("project", "projectName")
        set_name("staff", "staffName")

    elif collection == "page":
        set_name("project", "projectName")
        set_name("createdBy", "createdByName")
        set_name("business", "businessName")
        # Linked arrays could contain ids only; surface counts
        if isinstance(doc.get("linkedCycle"), list):
            out["linkedCycleCount"] = len(doc["linkedCycle"])  # type: ignore[index]
        if isinstance(doc.get("linkedModule"), list):
            out["linkedModuleCount"] = len(doc["linkedModule"])  # type: ignore[index]
        # Also surface names if available
        set_names_list("linkedCycle", "linkedCycleNames")
        set_names_list("linkedModule", "linkedModuleNames")

    elif collection == "projectState":
        # Keep core fields and slim subStates
        substates = doc.get("subStates")
        if isinstance(substates, list):
            slim: List[Dict[str, Any]] = []
            for s in substates:
                if isinstance(s, dict):
                    entry: Dict[str, Any] = {}
                    if isinstance(s.get("name"), str):
                        entry["name"] = s["name"]
                    if isinstance(s.get("order"), (int, float)):
                        entry["order"] = s["order"]
                    if entry:
                        slim.append(entry)
            if slim:
                out["subStates"] = slim

    # Drop empty/None values and metadata keys
    out = {k: v for k, v in out.items() if v not in (None, "", [], {}) and k != "_class"}
    return out


def filter_and_transform_content(data: Any, primary_entity: Optional[str] = None) -> Any:
    """Preserve meaningful fields, strip IDs/UUIDs, and flatten references per collection.

    Steps:
    1) Use existing filter to keep meaningful content fields.
    2) Strip any remaining id/uuid-like keys/values.
    3) Apply per-collection flatteners to surface human-friendly names.
    """
    base = filter_meaningful_content(data)
    stripped = _strip_ids(base)

    def enrich(obj: Any) -> Any:
        if isinstance(obj, dict):
            # Merge base with collection-specific projection
            extra = _transform_by_collection(obj, primary_entity)
            # Overlay extra on top of obj (extra wins)
            merged = {**obj, **extra}
            return {k: v for k, v in merged.items() if v not in (None, "", [], {})}
        return obj

    if isinstance(stripped, list):
        return [enrich(x) for x in stripped]
    if isinstance(stripped, dict):
        return enrich(stripped)
    return stripped


@tool
async def mongo_query(query: str, show_all: bool = False, enable_complex_joins: bool = True) -> str:
    """Plan-first Mongo query executor for structured, factual questions.

    Use this ONLY when the user asks for authoritative data that must come from
    MongoDB (counts, lists, filters, group-by, state/assignee/project details)
    across collections: `project`, `workItem`, `cycle`, `module`, `members`,
    `page`, `projectState`.

    Do NOT use this for:
    - Free-form content questions (use `rag_answer_question` or `rag_content_search`).
    - Pure summarization or opinion without data retrieval.
    - When you already have the exact answer in prior tool results.

    Behavior:
    - Follows a planner to generate a safe aggregation pipeline; avoids
      hallucinated fields.
    - Can generate complex aggregation pipelines with multiple joins when
      enable_complex_joins=True (default), reducing need for tool chaining.
    - Return concise summaries by default; pass `show_all=True` only when the
      user explicitly requests full records.

    Args:
        query: Natural language, structured data request about PM entities.
        show_all: If True, output full details instead of a summary. Use sparingly.
        enable_complex_joins: If True, allows complex multi-collection aggregation pipelines.

    Returns: A compact result suitable for direct user display.
    """
    if not plan_and_execute_query:
        return "‚ùå Intelligent query planner not available. Please ensure query_planner.py is properly configured."

    try:
        result = await plan_and_execute_query(query, enable_complex_joins=enable_complex_joins)

        if result["success"]:
            response = f"üéØ INTELLIGENT QUERY RESULT:\n"
            response += f"Query: '{query}'\n\n"

            # Show parsed intent
            intent = result["intent"]
            response += f"üìã UNDERSTOOD INTENT:\n"
            if result.get("planner"):
                response += f"‚Ä¢ Planner: {result['planner']}\n"
            response += f"‚Ä¢ Primary Entity: {intent['primary_entity']}\n"
            if intent['target_entities']:
                response += f"‚Ä¢ Related Entities: {', '.join(intent['target_entities'])}\n"
            if intent['filters']:
                response += f"‚Ä¢ Filters: {intent['filters']}\n"
            if intent['aggregations']:
                response += f"‚Ä¢ Aggregations: {', '.join(intent['aggregations'])}\n"
            response += "\n"

            # Show the generated pipeline (first few stages)
            pipeline = result.get("pipeline")
            pipeline_js = result.get("pipeline_js")
            if pipeline_js:
                response += f"üîß GENERATED PIPELINE:\n"
                response += pipeline_js
                response += "\n"
            elif pipeline:
                response += f"üîß GENERATED PIPELINE:\n"
                # Import the formatting function from planner
                try:
                    from planner import _format_pipeline_for_display
                    formatted_pipeline = _format_pipeline_for_display(pipeline)
                    response += formatted_pipeline
                except ImportError:
                    # Fallback to JSON format if import fails
                    for i, stage in enumerate(pipeline):
                        stage_name = list(stage.keys())[0]
                        # Format the stage content nicely
                        stage_content = json.dumps(stage[stage_name], indent=2)
                        # Truncate very long content for readability but show complete structure
                        if len(stage_content) > 200:
                            stage_content = stage_content + "..."
                        response += f"‚Ä¢ {stage_name}: {stage_content}\n"
                response += "\n"

            # Show results (compact preview)
            rows = result.get("result")
            try:
                # Attempt to parse stringified JSON results
                if isinstance(rows, str):
                    parsed = json.loads(rows)
                else:
                    parsed = rows
            except Exception:
                parsed = rows

            # Handle the specific MongoDB response format
            if isinstance(parsed, list) and len(parsed) > 0:
                # Check if first element is a string (like "Found X documents...")
                if isinstance(parsed[0], str) and parsed[0].startswith("Found"):
                    # This is the MongoDB response format: [message, doc1_json, doc2_json, ...]
                    # Parse the JSON strings and filter them
                    documents = []
                    for item in parsed[1:]:  # Skip the first message
                        if isinstance(item, str):
                            try:
                                doc = json.loads(item)
                                filtered_doc = filter_meaningful_content(doc)
                                if filtered_doc:  # Only add if there's meaningful content
                                    documents.append(filtered_doc)
                            except Exception:
                                # Skip invalid JSON
                                continue
                        else:
                            # Already parsed, filter directly
                            filtered_doc = filter_meaningful_content(item)
                            if filtered_doc:
                                documents.append(filtered_doc)

                    filtered = documents
                else:
                    # Regular list, filter as before
                    filtered = parsed
            else:
                # Not a list, filter as before
                filtered = parsed


            def format_llm_friendly(data, max_items=20, primary_entity: Optional[str] = None):
                """Format data in a more LLM-friendly way to avoid hallucinations."""
                def get_nested(d: Dict[str, Any], key: str) -> Any:
                    if key in d:
                        return d[key]
                    if "." in key:
                        cur: Any = d
                        for part in key.split("."):
                            if isinstance(cur, dict) and part in cur:
                                cur = cur[part]
                            else:
                                return None
                        return cur
                    return None

                def ensure_list_str(val: Any) -> List[str]:
                    if isinstance(val, list):
                        res: List[str] = []
                        for x in val:
                            if isinstance(x, str) and x.strip():
                                res.append(x)
                            elif isinstance(x, dict):
                                n = x.get("name") or x.get("title")
                                if isinstance(n, str) and n.strip():
                                    res.append(n)
                        return res
                    if isinstance(val, dict):
                        n = val.get("name") or val.get("title")
                        return [n] if isinstance(n, str) and n.strip() else []
                    if isinstance(val, str) and val.strip():
                        return [val]
                    return []

                def truncate_str(s: Any, limit: int = 120) -> str:
                    if not isinstance(s, str):
                        return str(s)
                    return s if len(s) <= limit else s[:limit] + "..."

                def render_line(entity: Dict[str, Any]) -> str:
                    e = (primary_entity or "").lower()
                    if e == "workitem":
                        bug = entity.get("displayBugNo") or entity.get("title") or "Item"
                        title = entity.get("title") or entity.get("name") or ""
                        state = entity.get("stateName") or get_nested(entity, "state.name")
                        project = entity.get("projectName") or get_nested(entity, "project.name")
                        assignees = ensure_list_str(entity.get("assignees") or entity.get("assignee"))
                        priority = entity.get("priority")
                        return f"‚Ä¢ {bug}: {truncate_str(title, 80)} ‚Äî state={state or 'N/A'}, priority={priority or 'N/A'}, assignee={(assignees[0] if assignees else 'N/A')}, project={project or 'N/A'}"
                    if e == "project":
                        pid = entity.get("projectDisplayId")
                        name = entity.get("name") or entity.get("title")
                        status_v = entity.get("status")
                        lead = entity.get("leadName") or get_nested(entity, "lead.name")
                        business = entity.get("businessName") or get_nested(entity, "business.name")
                        return f"‚Ä¢ {pid or name}: {name or ''} ‚Äî status={status_v or 'N/A'}, lead={lead or 'N/A'}, business={business or 'N/A'}"
                    if e == "cycle":
                        title = entity.get("title") or entity.get("name")
                        status_v = entity.get("status")
                        project = entity.get("projectName") or get_nested(entity, "project.name")
                        sd = entity.get("startDate")
                        ed = entity.get("endDate")
                        dates = f"{sd} ‚Üí {ed}" if sd or ed else "N/A"
                        return f"‚Ä¢ {truncate_str(title or 'Cycle', 80)} ‚Äî status={status_v or 'N/A'}, project={project or 'N/A'}, dates={dates}"
                    if e == "module":
                        title = entity.get("title") or entity.get("name")
                        project = entity.get("projectName") or get_nested(entity, "project.name")
                        assignees = ensure_list_str(entity.get("assignees") or entity.get("assignee"))
                        business = entity.get("businessName") or get_nested(entity, "business.name")
                        return f"‚Ä¢ {truncate_str(title or 'Module', 80)} ‚Äî project={project or 'N/A'}, assignees={(len(assignees) if assignees else 0)}, business={business or 'N/A'}"
                    if e == "members":
                        name = entity.get("name")
                        email = entity.get("email")
                        role = entity.get("role")
                        project = entity.get("projectName") or get_nested(entity, "project.name")
                        type_v = entity.get("type")
                        return f"‚Ä¢ {name or 'Member'} ‚Äî role={role or 'N/A'}, email={email or 'N/A'}, type={type_v or 'N/A'}, project={project or 'N/A'}"
                    if e == "page":
                        title = entity.get("title") or entity.get("name")
                        project = entity.get("projectName") or get_nested(entity, "project.name")
                        visibility = entity.get("visibility")
                        fav = entity.get("isFavourite")
                        return f"‚Ä¢ {truncate_str(title or 'Page', 80)} ‚Äî visibility={visibility or 'N/A'}, favourite={fav if fav is not None else 'N/A'}, project={project or 'N/A'}"
                    if e == "projectstate":
                        name = entity.get("name")
                        icon = entity.get("icon")
                        subs = entity.get("subStates")
                        sub_count = len(subs) if isinstance(subs, list) else 0
                        return f"‚Ä¢ {name or 'State'} ‚Äî icon={icon or 'N/A'}, substates={sub_count}"
                    # Default fallback
                    title = entity.get("title") or entity.get("name") or "Item"
                    return f"‚Ä¢ {truncate_str(title, 80)}"
                if isinstance(data, list):
                    # Handle count-only results
                    if len(data) == 1 and isinstance(data[0], dict) and "total" in data[0]:
                        return f"üìä RESULTS:\nTotal: {data[0]['total']}"

                    # Handle grouped/aggregated results
                    if len(data) > 0 and isinstance(data[0], dict) and "count" in data[0]:
                        response = "üìä RESULTS SUMMARY:\n"
                        total_items = sum(item.get('count', 0) for item in data)

                        # Determine what type of grouping this is
                        first_item = data[0]
                        group_keys = [k for k in first_item.keys() if k not in ['count', 'items']]

                        if group_keys:
                            response += f"Found {total_items} items grouped by {', '.join(group_keys)}:\n\n"

                            # Sort by count (highest first) and show more groups
                            sorted_data = sorted(data, key=lambda x: x.get('count', 0), reverse=True)

                            # Show all groups if max_items is None, otherwise limit
                            display_limit = len(sorted_data) if max_items is None else 15
                            for item in sorted_data[:display_limit]:
                                group_values = [f"{k}: {item[k]}" for k in group_keys if k in item]
                                group_label = ', '.join(group_values)
                                count = item.get('count', 0)
                                response += f"‚Ä¢ {group_label}: {count} items\n"

                            if max_items is not None and len(data) > 15:
                                remaining = sum(item.get('count', 0) for item in sorted_data[15:])
                                response += f"‚Ä¢ ... and {len(data) - 15} other categories: {remaining} items\n"
                            elif max_items is None and len(data) > display_limit:
                                remaining = sum(item.get('count', 0) for item in sorted_data[display_limit:])
                                response += f"‚Ä¢ ... and {len(data) - display_limit} other categories: {remaining} items\n"
                        else:
                            response += f"Found {total_items} items\n"
                        print(response)
                        return response

                    # Handle list of documents - show summary instead of raw JSON
                    if max_items is not None and len(data) > max_items:
                        response = f"üìä RESULTS SUMMARY:\n"
                        response += f"Found {len(data)} items. Showing key details for first {max_items}:\n\n"
                        # Show sample items in a collection-aware way
                        for i, item in enumerate(data[:max_items], 1):
                            if isinstance(item, dict):
                                response += render_line(item) + "\n"
                        if len(data) > max_items:
                            response += f"‚Ä¢ ... and {len(data) - max_items} more items\n"
                        return response
                    else:
                        # Show all items or small list - show in formatted way
                        response = "üìä RESULTS:\n"
                        for item in data:
                            if isinstance(item, dict):
                                response += render_line(item) + "\n"
                        return response

                # Single document or other data
                if isinstance(data, dict):
                    # Format single document in a readable way
                    response = "üìä RESULT:\n"
                    # Prefer a single-line summary first
                    if isinstance(data, dict):
                        response += render_line(data) + "\n\n"
                    # Then show key fields compactly (truncate long strings)
                    for key, value in data.items():
                        if isinstance(value, (str, int, float, bool)):
                            response += f"‚Ä¢ {key}: {truncate_str(value, 140)}\n"
                        elif isinstance(value, dict):
                            # Show only shallow summary for dict
                            name_val = value.get('name') or value.get('title')
                            if name_val:
                                response += f"‚Ä¢ {key}: {truncate_str(name_val, 120)}\n"
                            else:
                                child_keys = ", ".join(list(value.keys())[:5])
                                response += f"‚Ä¢ {key}: {{ {child_keys} }}\n"
                        elif isinstance(value, list):
                            if len(value) <= 5:
                                response += f"‚Ä¢ {key}: {truncate_str(str(value), 160)}\n"
                            else:
                                response += f"‚Ä¢ {key}: [{len(value)} items]\n"
                    return response
                else:
                    # Fallback to JSON for other data types
                    return f"üìä RESULTS:\n{json.dumps(data, indent=2)}"

            # Apply strong filter/transform now that we know the primary entity
            primary_entity = intent.get('primary_entity') if isinstance(intent, dict) else None
            filtered = filter_and_transform_content(filtered, primary_entity=primary_entity)

            # Format in LLM-friendly way
            max_items = None if show_all else 20
            formatted_result = format_llm_friendly(filtered, max_items=max_items, primary_entity=primary_entity)
            # If members primary entity and no rows, proactively hint about filters
            try:
                if isinstance(result.get("intent"), dict) and result["intent"].get("primary_entity") == "members" and not filtered:
                    formatted_result += "\n(No members matched. Try filtering by name, role, type, or project.)"
            except Exception:
                pass
            response += formatted_result
            print(response)
            return response
        else:
            return f"‚ùå QUERY FAILED:\nQuery: '{query}'\nError: {result['error']}"

    except Exception as e:
        return f"‚ùå INTELLIGENT QUERY ERROR:\nQuery: '{query}'\nError: {str(e)}"


@tool
async def rag_content_search(query: str, content_type: str = None, limit: int = 5) -> str:
    """Retrieve relevant content snippets for inspection (not final answers).

    Use to locate semantically relevant `page` or `work_item` snippets via RAG
    when the user asks to "search/find/show examples" or when you need context
    BEFORE answering. Prefer `rag_answer_question` when the user asks a direct
    question that needs synthesized context.

    Do NOT use this for:
    - Structured database facts (use `mongo_query`).
    - Producing the final answer. This returns excerpts to read, not conclusions.
    - Large limits by default; keep `limit` small (<= 5) unless the user asks.

    Args:
        query: Search phrase to find related content.
        content_type: 'page' | 'work_item' | None (both).
        limit: How many snippets to show (default 5).

    Returns: Snippets with scores to inform subsequent reasoning.
    """
    try:
        # rag_tool = RAGTool()
        rag_tool = RAGTool.get_instance()
        results = await rag_tool.search_content(query, content_type=content_type, limit=limit)

        if not results:
            return f"‚ùå No relevant content found for query: '{query}'"

        # Format response
        response = f"üîç RAG SEARCH RESULTS for '{query}':\n\n"
        response += f"Found {len(results)} relevant content pieces:\n\n"

        for i, result in enumerate(results, 1):
            response += f"[{i}] {result['content_type'].upper()}: {result['title']}\n"
            response += f"Relevance Score: {result['score']:.3f}\n"
            response += f"Content Preview: {result['content'][:300]}{'...' if len(result['content']) > 300 else ''}\n"

            # if result['metadata']:
            #     response += f"Metadata: {json.dumps(result['metadata'], indent=2)}\n"

            response += "\n" + "="*50 + "\n"

        return response

    except ImportError:
        return "‚ùå RAG functionality not available. Please install qdrant-client and sentence-transformers."
    except Exception as e:
        return f"‚ùå RAG SEARCH ERROR:\nQuery: '{query}'\nError: {str(e)}"


@tool
async def rag_answer_question(question: str, content_types: List[str] = None) -> str:
    """Assemble compact context to answer a content question (RAG-first).

    Use when the user asks a direct question about content in `page`/`work_item`
    data and you need short, high-signal context to support your answer.

    Do NOT use this for:
    - Structured facts like counts/groupings (use `mongo_query`).
    - Broad content discovery (use `rag_content_search`).

    Behavior:
    - Gathers a few high-relevance snippets and returns them as context to read.
    - Keep the final answer in the agent message; this tool returns only context.

    Args:
        question: The specific content question to answer.
        content_types: Optional list of ['page','work_item']; defaults to both.

    Returns: Concise context snippets for the agent to read and then answer.
    """
    try:
        rag_tool = RAGTool.get_instance()
        context = await rag_tool.get_content_context(question, content_types)

        if not context or "No relevant content found" in context:
            return f"‚ùå No relevant context found for question: '{question}'"

        response = f"üìñ CONTEXT FOR QUESTION: '{question}'\n\n"
        response += "Relevant content found:\n\n"
        response += context
        response += "\n" + "="*50 + "\n"
        response += "Use this context to answer the question about page and work item content."

        return response

    except ImportError:
        return "‚ùå RAG functionality not available. Please install qdrant-client and sentence-transformers."
    except Exception as e:
        return f"‚ùå RAG QUESTION ERROR:\nQuestion: '{question}'\nError: {str(e)}"


@tool
async def rag_to_mongo_workitems(query: str, limit: int = 20) -> str:
    """Bridge free-text to canonical work item records (RAG ‚Üí Mongo).

    Use when the user describes issues in prose and wants real work items with
    authoritative fields (e.g., `state.name`, `assignee`, `project.name`). This
    first vector-matches likely items, then fetches official records from Mongo.

    Do NOT use this for:
    - Pure semantic browsing without mapping to Mongo (use `rag_content_search`).
    - Arbitrary entities other than work items.

    Args:
        query: Free-text description to match work items.
        limit: Maximum records to return (keep modest; default 20).

    Returns: Brief lines summarizing matched items with canonical fields.
    """
    try:
        # Step 1: RAG search for work items only
        rag_tool = RAGTool.get_instance()
        rag_results = await rag_tool.search_content(query, content_type="work_item", limit=max(limit, 5))

        # Extract unique Mongo IDs and titles from RAG results (point id is mongo_id)
        all_ids: List[str] = []
        titles: List[str] = []
        seen_ids: set[str] = set()
        for r in rag_results:
            mongo_id = str(r.get("mongo_id") or r.get("id") or "").strip()
            title = str(r.get("title") or "").strip()
            if mongo_id and mongo_id not in seen_ids:
                seen_ids.add(mongo_id)
                all_ids.append(mongo_id)
            if title:
                titles.append(title)

        # Partition IDs: keep only 24-hex strings for ObjectId conversion; ignore UUIDs here
        object_id_strings = [s for s in all_ids if len(s) == 24 and all(c in '0123456789abcdefABCDEF' for c in s)]
        object_id_strings = object_id_strings[: max(0, limit)]
        # Deduplicate and cap titles
        seen_titles: set[str] = set()
        title_patterns: List[str] = []
        for t in titles:
            if t and t not in seen_titles:
                seen_titles.add(t)
                title_patterns.append(t)
            if len(title_patterns) >= max(0, limit):
                break

        # Helper builders
        def build_match_from_ids_and_titles(ids: List[str], title_list: List[str]) -> Dict[str, Any]:
            or_clauses_local: List[Dict[str, Any]] = []
            if ids:
                id_array_expr = {
                    "$map": {
                        "input": ids,
                        "as": "id",
                        "in": {"$toObjectId": "$$id"}
                    }
                }
                or_clauses_local.append({"$expr": {"$in": ["$_id", id_array_expr]}})
            if title_list:
                # Use escaped regex to avoid pathological patterns
                title_or = [{"title": {"$regex": re.escape(t), "$options": "i"}} for t in title_list if t]
                if title_or:
                    or_clauses_local.append({"$or": title_or})
            if not or_clauses_local:
                return {"$match": {"_id": {"$exists": True}}}  # no-op match
            if len(or_clauses_local) == 1:
                return {"$match": or_clauses_local[0]}
            return {"$match": {"$or": or_clauses_local}}

        def project_stage() -> Dict[str, Any]:
            return {
                "$project": {
                    "_id": 1,
                    "displayBugNo": 1,
                    "title": 1,
                    "state.name": 1,
                    "assignee.name": 1,
                    "project.name": 1,
                    "createdTimeStamp": 1,
                }
            }

        def parse_mcp_rows(rows_any: Any) -> List[Dict[str, Any]]:
            try:
                parsed_local = json.loads(rows_any) if isinstance(rows_any, str) else rows_any
            except Exception:
                parsed_local = rows_any
            docs_local: List[Dict[str, Any]] = []
            if isinstance(parsed_local, list) and parsed_local:
                if isinstance(parsed_local[0], str) and parsed_local[0].startswith("Found"):
                    for item in parsed_local[1:]:
                        if isinstance(item, str):
                            try:
                                doc = json.loads(item)
                                if isinstance(doc, dict):
                                    docs_local.append(doc)
                            except Exception:
                                continue
                        elif isinstance(item, dict):
                            docs_local.append(item)
                else:
                    # Filter only dicts
                    docs_local = [d for d in parsed_local if isinstance(d, dict)]
            elif isinstance(parsed_local, dict):
                docs_local = [parsed_local]
            else:
                docs_local = []
            return docs_local

        # Step 2: First attempt ‚Äî match by RAG object IDs and RAG titles
        primary_match = build_match_from_ids_and_titles(object_id_strings, title_patterns)
        pipeline = [
            primary_match,
            project_stage(),
            {"$limit": limit}
        ]

        args = {
            "database": DATABASE_NAME,
            "collection": "workItem",
            "pipeline": pipeline,
        }

        rows = await mongodb_tools.execute_tool("aggregate", args)

        # Normalize and produce a compact summary
        docs = parse_mcp_rows(rows)

        # Fallback 1: If nothing matched via IDs/titles, try Mongo text search
        if not docs:
            text_pipeline = [
                {"$match": {"$text": {"$search": query}}},
                project_stage(),
                {"$limit": limit}
            ]
            rows_text = await mongodb_tools.execute_tool("aggregate", {
                "database": DATABASE_NAME,
                "collection": "workItem",
                "pipeline": text_pipeline,
            })
            docs = parse_mcp_rows(rows_text)

        # Fallback 2: Regex across common fields and tokens
        if not docs:
            tokens = [w for w in re.findall(r"[A-Za-z0-9_]+", query) if w]
            field_list = ["title", "description", "state.name", "project.name", "cycle.name", "modules.name"]
            and_conditions: List[Dict[str, Any]] = []
            for tok in tokens:
                or_fields = [{fld: {"$regex": re.escape(tok), "$options": "i"}} for fld in field_list]
                and_conditions.append({"$or": or_fields})
            regex_match = {"$match": {"$and": and_conditions}} if and_conditions else {"$match": {"_id": {"$exists": True}}}
            regex_pipeline = [
                regex_match,
                project_stage(),
                {"$limit": limit}
            ]
            rows_regex = await mongodb_tools.execute_tool("aggregate", {
                "database": DATABASE_NAME,
                "collection": "workItem",
                "pipeline": regex_pipeline,
            })
            docs = parse_mcp_rows(rows_regex)

        if not docs:
            return f"‚ùå No MongoDB records found for the RAG matches or fallbacks of '{query}'"

        # Keep content meaningful
        cleaned = filter_and_transform_content(docs, primary_entity="workItem")

        # Render
        lines = [f"üîó Matches for '{query}':"]
        for i, d in enumerate(cleaned[:limit], 1):
            if not isinstance(d, dict):
                continue
            bug = d.get("displayBugNo") or d.get("title") or f"Item {i}"
            title = d.get("title", "(no title)")
            state = d.get("stateName") or ((d.get("state") or {}).get("name") if isinstance(d.get("state"), dict) else d.get("state"))
            # assignee may be array or object depending on schema; try best-effort
            assignee_val = d.get("assignee")
            if isinstance(assignee_val, dict):
                assignee = assignee_val.get("name")
            elif isinstance(assignee_val, list) and assignee_val and isinstance(assignee_val[0], dict):
                assignee = assignee_val[0].get("name")
            else:
                assignee = (d.get("assignees") or [None])[0] if isinstance(d.get("assignees"), list) else None
            lines.append(f"‚Ä¢ {bug}: {title} ‚Äî state={state or 'N/A'}, assignee={assignee or 'N/A'}")

        return "\n".join(lines)

    except ImportError:
        return "‚ùå RAG functionality not available. Please install qdrant-client and sentence-transformers."
    except Exception as e:
        return f"‚ùå RAG‚ÜíMongo ERROR:\nQuery: '{query}'\nError: {str(e)}"

        # This function has been removed. Keep a stub to avoid import-time surprises.
        return "‚ùå composite_query has been removed. Use mongo_query and agent routing instead."
    except Exception as e:
        return f"‚ùå Composite query error: {e}"

# Define the tools list (no schema tool)
tools = [
    mongo_query,
    rag_content_search,
    rag_answer_question,
    rag_to_mongo_workitems,
]

# import asyncio

# if __name__ == "__main__":
#     async def main():
#         # Test the tools    
#         while True:
#             question = input("Enter your question: ")
#             if question.lower() in ['exit', 'quit']:
#                 break

#             print("\nüéØ Testing intelligent_query...")

#             print("üîç Testing rag_content_search...")
#             result1 = await rag_content_search.ainvoke({
#                 "query": question,   # rag_content_search expects `query`
#             })
#             print(result1)

#             print("\nüìñ Testing rag_answer_question...")
#             result2 = await rag_answer_question.ainvoke({
#                 "question": question,   # rag_answer_question expects `question`
#             })
#             print(result2)

#     asyncio.run(main())
